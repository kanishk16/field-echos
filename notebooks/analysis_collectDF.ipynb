{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Dataframes\n",
    "This notebook collects the FOOOF results and compiles them into a dataframe, for both the macaque and human data, separately, to be analyzed/visualized in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import io\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import nibabel as nib\n",
    "\n",
    "sys.path.append('../')\n",
    "import echo_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global parameters for which fooof results to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect FOOOF results that were produced under these parameters\n",
    "win_len, p_cur = '1sec', 'psd_med'\n",
    "fg_param_to_load = 'knee'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Macaque ECoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cortex files for electrode coordinates\n",
    "chibi_ctx_file = '/Users/rdgao/Documents/data/NeuroTycho/Propofol/GridLocations/20110621KTMD_Anesthesia+and+Sleep_Chibi_Toru+Yanagawa_mat_2Dimg/ChibiMap.mat'\n",
    "george_ctx_file = '/Users/rdgao/Documents/data/NeuroTycho/Propofol/GridLocations/20110112KTMD_Anesthesia+and+Sleep_George_Toru+Yanagawa_mat_2Dimg/GeorgeMap.mat'\n",
    "ctx_loc = []\n",
    "for ind, ctx_file in enumerate([chibi_ctx_file, george_ctx_file]):\n",
    "    ctx_mat = io.loadmat(ctx_file, squeeze_me=True)\n",
    "    ctx_loc.append(np.array([ctx_mat['X'], ctx_mat['Y']]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../echo_utils.py:59: RuntimeWarning: invalid value encountered in power\n",
      "  knee_freq = knee**(1./exponent)\n"
     ]
    }
   ],
   "source": [
    "# collection\n",
    "df_savepath = '../data/df_macaque'\n",
    "df_combined = pd.DataFrame()\n",
    "col_names = ['patient','cond','pharm', 'session_id', 'chan', 'exp', 'knee', 'tau','log_tau','err', 'r2']\n",
    "\n",
    "# load fooof results\n",
    "result_basepath = '/Users/rdgao/Documents/code/research/field-echos/results/neurotycho/rest_anes/'\n",
    "session_resultpath = np.sort([f+'/' for f in os.listdir(result_basepath) if os.path.isdir(result_basepath+f)])\n",
    "session_dict = {id:ind for ind, id in enumerate(np.unique([s.split('_')[3] for s in session_resultpath]))}\n",
    "\n",
    "for s in session_resultpath:\n",
    "    fooof_folder = result_basepath + s +'/psd/'+win_len+'/fooof/'+p_cur+'/'    \n",
    "    ff_list = [ff for ff in os.listdir(fooof_folder) if '.json' in ff]\n",
    "    ff_file = ff_list[np.where([fg_param_to_load in f for f in ff_list])[0][0]] # load specific fooof file\n",
    "    \n",
    "    # return fooof fits and convert knee to tau\n",
    "    fg_aps, fg_pks, fg_err, fg_r2s = echo_utils.return_fg_fits(ff_file, fooof_folder)\n",
    "    if fg_aps.shape[1]==3:\n",
    "        knee_freq, knee_tau = echo_utils.convert_knee_val(fg_aps[:,1],fg_aps[:,2])\n",
    "        knee = fg_aps[:,1]\n",
    "    else:\n",
    "        knee_tau = np.zeros_like(fg_aps[:,0])\n",
    "        knee = np.zeros_like(fg_aps[:,0])\n",
    "    \n",
    "    df_data = np.vstack((fg_aps[:,-1], knee, knee_tau, np.log10(knee_tau), fg_err, fg_r2s)).T\n",
    "    s_spl = s.split('_')\n",
    "    patient, cond, pharm, session_id = s_spl[7], s_spl[1], s_spl[2], session_dict[s_spl[3]]\n",
    "    chan = np.arange(len(fg_err))+1\n",
    "    df_cur = pd.DataFrame(np.hstack((np.repeat(np.array([patient,cond,pharm, session_id])[:,None].T, len(fg_err), axis=0), chan[:,None], df_data))\n",
    "                 ,columns=col_names)\n",
    "    df_cur.insert(5,'y', ctx_loc[0 if patient is 'Chibi' else 1][:,0])\n",
    "    df_cur.insert(6,'z', ctx_loc[0 if patient is 'Chibi' else 1][:,1])\n",
    "\n",
    "    df_combined = df_combined.append(df_cur, ignore_index=True)\n",
    "\n",
    "df_combined.columns\n",
    "df_combined = df_combined.astype({c:str if c in ['patient', 'cond', 'pharm'] else np.float for c in col_names})\n",
    "\n",
    "# saveout\n",
    "df_combined.to_csv(df_savepath+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Human ECoG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'AgeAtTimeOfStudy', 'ChannelName', 'ChannelPosition', 'ChannelRegion', 'ChannelType', 'Data', 'FacesLeft', 'FacesRight', 'Gender', 'Hemisphere', 'NodesLeft', 'NodesLeftInflated', 'NodesRegionLeft', 'NodesRegionRight', 'NodesRight', 'NodesRightInflated', 'Patient', 'RegionName', 'SamplingFrequency'])\n"
     ]
    }
   ],
   "source": [
    "# load the various data variables, elec loc, etc\n",
    "basepath = '/Users/rdgao/Documents/data/MNI_rest/'\n",
    "datafile = basepath + 'WakefulnessMatlabFile.mat'\n",
    "result_basepath = '/Users/rdgao/Documents/code/research/field-echos/results/MNI_rest/'\n",
    "df_savepath = '../data/df_human'\n",
    "\n",
    "data_dict = io.loadmat(datafile, squeeze_me = True) # data file that has all the meta info\n",
    "region_labels = pd.read_csv(basepath+'/WakefulnessInformation/RegionInformation.csv') # channel labels\n",
    "patient_info = pd.read_csv(basepath+'/WakefulnessInformation/PatientInformation.csv', index_col=0, names=['gender', 'age'], skiprows=1) # patient labels\n",
    "region_labels['Region name']=[rl[1:-1] for rl in region_labels['Region name']] # get rid of quotes\n",
    "print(data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: /Users/rdgao/Documents/code/research/field-echos/results/MNI_rest//psd/1sec/fooof/psd_med/\n",
      "Total electrodes: 1772\n",
      "Total electrodes after dropping nans: 1765\n",
      "Total patients: 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../echo_utils.py:59: RuntimeWarning: invalid value encountered in power\n",
      "  knee_freq = knee**(1./exponent)\n"
     ]
    }
   ],
   "source": [
    "# load fooof results, use same glboal settings as monkey ECoG\n",
    "fooof_folder = result_basepath+'/psd/'+win_len+'/fooof/'+p_cur+'/'\n",
    "print('Loading file: %s'%fooof_folder)\n",
    "ff_list = [ff for ff in os.listdir(fooof_folder) if '.json' in ff]\n",
    "ff_file = ff_list[np.where([fg_param_to_load in f for f in ff_list])[0][0]] # load specific fooof file\n",
    "\n",
    "# return fooof fits and convert knee to tau\n",
    "fg_aps, fg_pks, fg_err, fg_r2s = echo_utils.return_fg_fits(ff_file, fooof_folder)\n",
    "if fg_aps.shape[1]==3:\n",
    "    knee_freq, knee_tau = echo_utils.convert_knee_val(fg_aps[:,1],fg_aps[:,2])\n",
    "    knee = fg_aps[:,1]\n",
    "else:\n",
    "    knee_tau = np.zeros_like(fg_aps[:,0])\n",
    "    knee = np.zeros_like(fg_aps[:,0])\n",
    "\n",
    "# create pandas df and throw everything in there\n",
    "e_type = np.array(data_dict['ChannelType'], 'c').view(np.uint8)-64.\n",
    "#patient_info['gender'] = 0 if 'M' else 1\n",
    "patient_info.replace(['M','F'], [0,1], inplace=True)\n",
    "df_info = np.vstack((data_dict['Patient'], \n",
    "                     patient_info.loc[data_dict['Patient']][['gender', 'age']].values.astype(int).T, \n",
    "                     e_type, \n",
    "                     data_dict['ChannelPosition'].T, \n",
    "                     data_dict['ChannelRegion'])\n",
    "                   ).T\n",
    "df_data = np.vstack((fg_aps[:,-1], knee, knee_tau, np.log10(knee_tau), fg_err, fg_r2s)).T\n",
    "df_combined = pd.DataFrame(np.hstack((df_info,df_data)),columns=['patient','gender','age','etype', 'x','y','z','region','exp', 'knee', 'tau','log_tau','err', 'r2'])\n",
    "\n",
    "# insert column for x_positive (collapse across L-R axis)\n",
    "df_combined.insert(5, 'x_pos', np.abs(df_combined['x'].values))\n",
    "\n",
    "# insert lobe info\n",
    "df_combined.insert(8, 'lobe', 0)\n",
    "lobe_id = {val: ind for ind, val in enumerate(region_labels['Lobe'].unique())}\n",
    "for ind, region in enumerate(region_labels['Region #']):\n",
    "    df_combined.loc[df_combined['region']==region,'lobe'] = lobe_id[region_labels.loc[ind,'Lobe']]\n",
    "\n",
    "print('Total electrodes: %i'%len(df_combined))\n",
    "\n",
    "# drop nans\n",
    "df_combined.dropna(inplace=True)\n",
    "df_combined.reset_index(drop=True, inplace=True)\n",
    "print('Total electrodes after dropping nans: %i'%len(df_combined))\n",
    "\n",
    "## print some electrode type info and correlation\n",
    "# print(df_combined.groupby('etype').count()['patient'])\n",
    "# print(df_combined[['exp','knee','tau','log_tau', 'err', 'r2']].corr('spearman'))\n",
    "\n",
    "print('Total patients: %i'%len(df_combined['patient'].unique()))\n",
    "df_combined.to_csv(df_savepath+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save PSD plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_fits = False\n",
    "\n",
    "if plot_fits: plt.figure(figsize=(5,5))\n",
    "for win_len_iter in ['1sec', '5sec']:\n",
    "    for p_cur_iter in ['psd_mean', 'psd_med']:\n",
    "        # construct channel metainfo and behavioral table\n",
    "        psd_data = np.load(result_basepath+'/psd/'+win_len_iter+'/psds.npz')\n",
    "\n",
    "        # load fooof results\n",
    "        fooof_folder = result_basepath +'/psd/'+win_len_iter+'/fooof/'+p_cur_iter+'/'  \n",
    "        ff_list = [ff for ff in os.listdir(fooof_folder) if '.json' in ff]\n",
    "\n",
    "        # plot psds and all fits\n",
    "        if plot_fits:\n",
    "            fit_fig_path = utils.makedir(fooof_folder, '/plts/', False)\n",
    "            f_axis = psd_data['f_axis']\n",
    "            psds = psd_data[p_cur_iter].T\n",
    "            fg_labels = [f.split('.')[0][3:] for f in ff_list]\n",
    "            # grab fgs\n",
    "            fg_all=[]\n",
    "            for ff in ff_list:\n",
    "                fg_dummy = FOOOFGroup()\n",
    "                fg_dummy.load(fooof_folder+ff)\n",
    "                fg_all.append(fg_dummy)\n",
    "            # plot\n",
    "            for chan in range(psds.shape[0]):\n",
    "                utils.plot_psd_fits(f_axis, psds, chan, fg_all, fg_labels)\n",
    "                plt.title('Channel: %i - Region: %i'%(chan, data_dict['ChannelRegion'][chan]))\n",
    "                fig_name = '/chan%i_reg%i.png'%(chan, data_dict['ChannelRegion'][chan])\n",
    "                plt.savefig(fit_fig_path+fig_name)\n",
    "                plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting T1w/T2w & gene expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nibabel as ni\n",
    "annot_file = '/Users/rdgao/mne_data/MNE-sample-data/subjects/fsaverage/label/lh.HCPMMP1.annot'\n",
    "mmp_labels, ctab, mmp_names = ni.freesurfer.read_annot(annot_file)\n",
    "\n",
    "anat_basepath = '/Users/rdgao/Documents/data/GeneMyelin/'\n",
    "df_savepath = '../data/df_structural'\n",
    "\n",
    "# load myelin data\n",
    "df_myelin = pd.read_csv(anat_basepath+'Glasser_labels_L.txt', sep='\\t', index_col=0, header=None, names=['region'])\n",
    "df_myelin['region']=region_names\n",
    "myelin_val = io.loadmat(anat_basepath+'myelin.mat', squeeze_me=True)['myelin']\n",
    "df_myelin.insert(loc=1, column='T1T2', value=myelin_val)\n",
    "\n",
    "# load gene expression data\n",
    "gene_data = io.loadmat(anat_basepath+'gdat.mat', squeeze_me=True)\n",
    "df_gene= pd.DataFrame(gene_data['gdat'].T, columns=gene_data['lab'][:,0])\n",
    "\n",
    "# combine\n",
    "df_anat = pd.concat((df_myelin.reset_index()[['region', 'T1T2']], df_gene), axis=1)\n",
    "df_anat.index+=1\n",
    "\n",
    "df_anat.to_csv(df_savepath+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aligning ECoG (MNI) and Structural (Glasser) data\n",
    "The ECoG electrodes locations are given in (volumetric) MNI space, where as the myelination & expression data are given for surface Glasser parcellation. To compare the two datasets, and in general visualizing the ECoG data spatially, we have to align them to the same space.\n",
    "\n",
    "This can be done either through discrete assignments (1-to-1 or N-to-1), or upsampling into a common space and then smooth & aggregate back into either MNI or Glasser space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMP_data = nib.load(anat_basepath+'MMP 1.0 MNI projections/MMP_in_MNI_symmetrical_1.nii.gz')\n",
    "\n",
    "# since only <4% of voxels actually have non-zero parcellation values\n",
    "# we can reduce the map first and just search in the non-zero regions\n",
    "# reduce the map and find the indices where parcel value is non-zero\n",
    "MMP_map = np.asarray(MMP_data.get_data())\n",
    "MMP_sparse_coords = np.array(np.where(MMP_map>0)).T\n",
    "MMP_map_sparse_flat = MMP_map[np.where(MMP_map>0)]\n",
    "\n",
    "# r_search = 3\n",
    "# # transform to MMP indices\n",
    "# ecog_coors_transformed = np.array([echo_utils.apply_affine(MMP_data.affine, row[['x','y','z']].values, False) for r_i, row in df_combined.iterrows()])\n",
    "\n",
    "# # find the closest projection of ecog onto parcellation voxels within a radius\n",
    "# proj_dist_inds = echo_utils.project_ecog_mmp(ecog_coors_transformed, MMP_sparse_coords, r_search, find_nearest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsample, Smoothing & Project to MMP\n",
    "Here, we create a electrode distance-weighted map for each subject that's a function of a Gaussian where the weight drops to 50% at distance d. The weight is computed at every MNI-coordinate value at which there is a MMP parcel. The distance-weighted feature matrix (in this case, tau) is then computed as a weighted sum over all electrodes and grouped at the parcel level. This has two advantages: 1) electrodes near parcellation boundaries still contribute to the nearby parcels even if it doesn't fall within it, and 2) electrodes in the center of a parcellation contribute more to the parcel's value than electrodes at boundaries. \n",
    "\n",
    "W_sum and W_max record the sum and max of the weight within each parcel for every subject, as a measure of confidence of the largest contribution (how close the closest electrode is) that fell within the parcel.\n",
    "\n",
    "Original MATLAB code & idea for spatial smoothing with Gaussian courtesy of discussion with Thomas Pfeffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|2|3|4|5|6|7|8|9|10|11|"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rdgao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/Users/rdgao/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|87|88|89|90|91|92|93|94|96|97|98|99|100|101|102|103|104|106|107|108|109|110|"
     ]
    }
   ],
   "source": [
    "df_combined = pd.read_csv('../data/df_human.csv', index_col=0)\n",
    "\n",
    "# set smoothing parameter: Gaussian is at 50% when d voxels away\n",
    "d = 4\n",
    "d_alpha= d/(-np.log(0.5))**0.5\n",
    "\n",
    "output_grid = MMP_sparse_coords\n",
    "feature = 'exp'\n",
    "feat_weighted, W_sum, W_max = [],[],[]\n",
    "for i_p in np.unique(df_combined['patient']):\n",
    "    # iterate over patients\n",
    "    print(int(i_p), end='|')\n",
    "    df_patient = df_combined[df_combined['patient']==i_p]\n",
    "    \n",
    "    # get transformed ECoG coordinate\n",
    "    input_grid = np.array([echo_utils.apply_affine(MMP_data.affine, row[['x','y','z']].values, False) for r_i, row in df_patient.iterrows()])    \n",
    "\n",
    "    # create the weight matrix from input to output projection based on Gaussian weighting of Euclidean distance\n",
    "    W_mat = np.zeros((input_grid.shape[0],output_grid.shape[0]))\n",
    "    for ig in range(input_grid.shape[0]):\n",
    "        W_mat[ig,:] = np.exp(-np.linalg.norm(output_grid-input_grid[ig,:], axis=1)**2/d_alpha**2)\n",
    "\n",
    "    # get total and max weights to drop bad coverage points\n",
    "    W_sum.append(W_mat.sum(0)) \n",
    "    W_max.append(np.max(W_mat,0))\n",
    "    feat_weighted.append(np.dot(df_patient[feature].values, W_mat)/W_mat.sum(0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_names = [n[2:-4].decode(\"utf-8\") for n in mmp_names[1:]]\n",
    "\n",
    "# save parcellated feature matrix\n",
    "df_save = pd.DataFrame(np.array(feat_weighted).T, columns=np.unique(df_combined['patient']).astype(int))\n",
    "df_save.insert(0, 'parcel', MMP_map_sparse_flat)\n",
    "df_save.groupby('parcel').mean().T.to_csv('../data/df_human_%s_weighted_%i.csv'%(feature, d), header=region_names)\n",
    "\n",
    "# save parcellated weight matrix sum\n",
    "df_save = pd.DataFrame(np.array(W_sum).T, columns=np.unique(df_combined['patient']).astype(int))\n",
    "df_save.insert(0, 'parcel', MMP_map_sparse_flat)\n",
    "df_save.groupby('parcel').sum().T.to_csv('../data/df_human_W_sum_%i.csv'%d, header=region_names)\n",
    "\n",
    "# save parcellated weight matrix max\n",
    "df_save = pd.DataFrame(np.array(W_max).T, columns=np.unique(df_combined['patient']).astype(int))\n",
    "df_save.insert(0, 'parcel', MMP_map_sparse_flat)\n",
    "df_save = df_save.groupby('parcel').max().T.to_csv('../data/df_human_W_max_%i.csv'%d, header=region_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
